# -*- coding: utf-8 -*-
"""solutions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gX0EWYw2RAO_mll-JZsaKrEuyN2aAyRx
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

# Load the uploaded CSV files into DataFrames
users_df = pd.read_csv('users.csv')
repositories_df = pd.read_csv('repositories.csv')

# Display the first few rows of each DataFrame to check
print("Users Data:")
print(users_df.head())
print("\nRepositories Data:")
print(repositories_df.head())

"""1. Who are the top 5 users in Chicago with the highest number of followers? List their login in order, comma-separated.
Users
"""

# Sort by followers in descending order and select the top 5 users
top_5_users = users_df.sort_values(by='followers', ascending=False).head(5)

# Create a comma-separated list of their login names
top_5_users_logins = ", ".join(top_5_users['login'].tolist())
print("Top 5 users by followers:", top_5_users_logins)

"""Who are the 5 earliest registered GitHub users in Chicago? List their login in ascending order of created_at, comma-separated."""

earliest_5_users = users_df.sort_values(by='created_at', ascending=True).head(5)

# Create a comma-separated list of their login names
earliest_5_users_logins = ", ".join(earliest_5_users['login'].tolist())
print("5 earliest registered GitHub users in Chicago:", earliest_5_users_logins)

licensed_repos = repositories_df.dropna(subset=['license_name'])

# Count the occurrences of each license and get the top 3
top_3_licenses = licensed_repos['license_name'].value_counts().head(3).index.tolist()

# Create a comma-separated list of the top 3 license names
top_3_licenses_list = ", ".join(top_3_licenses)
print("3 most popular licenses:", top_3_licenses_list)

# Clean up company names
users_df['company'] = users_df['company'].fillna('').str.strip().str.upper()

# Identify the most common company
top_company = users_df['company'].value_counts().idxmax()
print("Company with the majority of developers:", top_company)

most_popular_language = repositories_df['language'].dropna().value_counts().idxmax()

print("Most popular programming language:", most_popular_language)

"""6. Which programming language is the second most popular among users who joined after 2020?"""

# Filter users who joined after 2020
recent_users = users_df[users_df['created_at'] > '2020-01-01']['login']

# Filter repositories for these recent users
recent_repos = repositories_df[repositories_df['login'].isin(recent_users)]

# Count occurrences of each programming language and get the second most popular
second_most_popular_language = recent_repos['language'].dropna().value_counts().index[1]

print("Second most popular programming language among users who joined after 2020:", second_most_popular_language)

language_avg_stars = repositories_df.groupby('language')['stargazers_count'].mean()

# Find the language with the highest average number of stars
highest_avg_stars_language = language_avg_stars.idxmax()
highest_avg_stars_value = language_avg_stars.max()

print("Language with the highest average stars per repository:", highest_avg_stars_language)
print("Average number of stars:", highest_avg_stars_value)

users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])

# Sort by leader_strength in descending order and select the top 5 users
top_5_leaders = users_df.sort_values(by='leader_strength', ascending=False).head(5)

# Create a comma-separated list of their login names
top_5_leader_logins = ", ".join(top_5_leaders['login'].tolist())
print("Top 5 users by leader_strength:", top_5_leader_logins)

# Calculate the correlation between 'followers' and 'public_repos'
followers_repos_correlation = users_df['followers'].corr(users_df['public_repos'])

# Round to 3 decimal places
followers_repos_correlation_rounded = round(followers_repos_correlation, 3)
print("Correlation between followers and public repositories:", followers_repos_correlation_rounded)

from sklearn.linear_model import LinearRegression

# Prepare the data for regression
X = users_df[['public_repos']]  # Independent variable
y = users_df['followers']       # Dependent variable

# Create and fit the linear regression model
model = LinearRegression()
model.fit(X, y)

# Extract the slope (coefficient) of the regression line
slope = model.coef_[0]

# Round to 3 decimal places
slope_rounded = round(slope, 3)
print("Regression slope of followers on repos:", slope_rounded)

# Convert 'has_projects' and 'has_wiki' columns to binary (1 for True, 0 for False)
repositories_df['has_projects'] = repositories_df['has_projects'].astype(int)
repositories_df['has_wiki'] = repositories_df['has_wiki'].astype(int)

# Calculate the correlation between 'has_projects' and 'has_wiki'
projects_wiki_correlation = repositories_df['has_projects'].corr(repositories_df['has_wiki'])

# Round to 3 decimal places
projects_wiki_correlation_rounded = round(projects_wiki_correlation, 3)
print("Correlation between projects and wiki enabled:", projects_wiki_correlation_rounded)

import pandas as pd

# Load the repositories.csv file
repositories_df = pd.read_csv('repositories.csv')

# Ensure no NaN values in 'has_projects' and 'has_wiki' columns
repositories_df = repositories_df.dropna(subset=['has_projects', 'has_wiki'])

# Convert 'has_projects' and 'has_wiki' columns to binary (1 for True, 0 for False)
repositories_df['has_projects'] = repositories_df['has_projects'].astype(int)
repositories_df['has_wiki'] = repositories_df['has_wiki'].astype(int)

# Calculate the correlation between 'has_projects' and 'has_wiki'
projects_wiki_correlation = repositories_df['has_projects'].corr(repositories_df['has_wiki'])

# Round to 3 decimal places
projects_wiki_correlation_rounded = round(projects_wiki_correlation, 3)
print("Correlation between projects and wiki enabled:", projects_wiki_correlation_rounded)

import pandas as pd

# Load the users.csv file
users_df = pd.read_csv('users.csv')

# Ensure 'hireable' column is correctly interpreted as a boolean
users_df['hireable'] = users_df['hireable'].astype(bool)

# Separate the DataFrame into hireable and non-hireable users
hireable_users = users_df[users_df['hireable'] == True]
non_hireable_users = users_df[users_df['hireable'] == False]

# Calculate the average number of people each group follows
average_following_hireable = hireable_users['following'].mean()
average_following_non_hireable = non_hireable_users['following'].mean()

# Calculate the difference in average following, rounded to 3 decimal places
difference_in_following = round(average_following_hireable - average_following_non_hireable, 3)
print("Difference in average following (hireable - non-hireable):", difference_in_following)

import pandas as pd
from sklearn.linear_model import LinearRegression

# Load the users.csv file
users_df = pd.read_csv('users.csv')

# Calculate the bio word count for each user (ignoring users without bios)
users_with_bios = users_df.dropna(subset=['bio']).copy()
users_with_bios['bio_word_count'] = users_with_bios['bio'].apply(lambda x: len(x.split()))

# Prepare data for regression
X = users_with_bios[['bio_word_count']]  # Independent variable (bio word count)
y = users_with_bios['followers']         # Dependent variable (followers)

# Create and fit the linear regression model
model = LinearRegression()
model.fit(X, y)

# Extract the slope (coefficient) of the regression line
bio_followers_slope = round(model.coef_[0], 3)
print("Regression slope of followers on bio word count:", bio_followers_slope)

import pandas as pd
from sklearn.linear_model import LinearRegression

# Load the users.csv file
users_df = pd.read_csv('users.csv')

# Filter users with non-empty bios and calculate bio word count
users_with_bios = users_df.dropna(subset=['bio']).copy()
users_with_bios['bio_word_count'] = users_with_bios['bio'].apply(lambda x: len(x.split()))

# Calculate the correlation between bio word count and followers
correlation_bio_followers = users_with_bios['bio_word_count'].corr(users_with_bios['followers'])
correlation_bio_followers_rounded = round(correlation_bio_followers, 3)

# Perform linear regression to find the slope (bio word count vs followers)
X = users_with_bios[['bio_word_count']]
y = users_with_bios['followers']

# Create and fit the linear regression model
model = LinearRegression()
model.fit(X, y)

# Extract the slope (coefficient) of the regression line and round to 3 decimal places
bio_followers_slope = round(model.coef_[0], 3)

# Print results
print("Correlation between bio word count and followers:", correlation_bio_followers_rounded)
print("Regression slope of followers on bio word count:", bio_followers_slope)

import pandas as pd

# Load the repositories.csv file
repositories_df = pd.read_csv('repositories.csv')

# Convert 'created_at' to datetime format in UTC
repositories_df['created_at'] = pd.to_datetime(repositories_df['created_at'], utc=True)

# Identify weekend repositories (Saturday and Sunday)
repositories_df['day_of_week'] = repositories_df['created_at'].dt.dayofweek  # Monday=0, Sunday=6
weekend_repos = repositories_df[repositories_df['day_of_week'] >= 5]  # 5 for Saturday, 6 for Sunday

# Count the number of weekend repositories per user
weekend_repo_counts = weekend_repos['login'].value_counts().head(5)

# Create a comma-separated list of the top 5 users' login names
top_5_weekend_creators = ", ".join(weekend_repo_counts.index.tolist())
print("Top 5 users with most repositories created on weekends:", top_5_weekend_creators)

import pandas as pd

# Load the users.csv file
users_df = pd.read_csv('users.csv')

# Filter hireable and non-hireable users
hireable_users = users_df[users_df['hireable'] == True]
non_hireable_users = users_df[users_df['hireable'] == False]

# Calculate fraction of users with email for hireable users
hireable_with_email_fraction = hireable_users['email'].notna().mean()

# Calculate fraction of users with email for non-hireable users
non_hireable_with_email_fraction = non_hireable_users['email'].notna().mean()

# Calculate the difference and round to 3 decimal places
email_fraction_difference = round(hireable_with_email_fraction - non_hireable_with_email_fraction, 3)
print("Difference in email sharing (hireable - non-hireable):", email_fraction_difference)

import pandas as pd

# Load the users.csv file
users_df = pd.read_csv('users.csv')

# Drop users with missing names and trim whitespace
users_with_names = users_df.dropna(subset=['name']).copy()
users_with_names['name'] = users_with_names['name'].str.strip()

# Extract the last word from each name as the surname
users_with_names['surname'] = users_with_names['name'].apply(lambda x: x.split()[-1])

# Find the most common surname(s)
surname_counts = users_with_names['surname'].value_counts()
max_count = surname_counts.max()
most_common_surnames = surname_counts[surname_counts == max_count].index.tolist()

# Join surnames alphabetically in case of a tie
most_common_surnames_sorted = ", ".join(sorted(most_common_surnames))

# Display the most common surname(s) and the number of users with that surname
print("Most common surname(s):", most_common_surnames_sorted)
print("Number of users with the most common surname:", max_count)