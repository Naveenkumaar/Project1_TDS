# -*- coding: utf-8 -*-
"""SCARPPING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R_lp_hc8TrNct5XNoqwB903rcoNuKEpk
"""

import requests

# GitHub API token
token = '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'
headers = {'Authorization': f'token {token}'}

import time

# Function to get users from Chicago with over 100 followers
def get_users_from_chicago():
    users = []
    url = 'https://api.github.com/search/users'
    params = {'q': 'location:Chicago followers:>99', 'per_page': 100}  # Using >99 instead of >=100 to ensure proper filtering

    while url:
        response = requests.get(url, headers=headers, params=params)
        if response.status_code != 200:
            print("Error fetching users:", response.status_code)
            break

        data = response.json()
        users.extend(data['items'])  # Add users to the list
        url = response.links.get('next', {}).get('url')  # Get the URL for the next page if available

        time.sleep(1)  # Short delay to avoid hitting the rate limit

    return users

# Fetch all users from Chicago with over 100 followers
users = get_users_from_chicago()

# Function to get repositories for a specific user
def get_repositories_for_user(user_login):
    repos = []
    url = f'https://api.github.com/users/{user_login}/repos'
    params = {'sort': 'pushed', 'per_page': 100}  # Get up to 100 repos per page, sorted by the most recently pushed
    while url:
        response = requests.get(url, headers=headers, params=params)
        if response.status_code != 200:
            print(f"Error fetching repos for {user_login}:", response.status_code)
            break
        data = response.json()
        repos.extend(data)
        url = response.links.get('next', {}).get('url')  # Get the URL for the next page if available
    return repos

# Fetch repositories for each user
all_repositories = []
for user in users:
    repos = get_repositories_for_user(user['login'])
    all_repositories.extend(repos)

# Clean company names
def clean_company(company):
    if company:
        company = company.strip().upper()
        if company.startswith('@'):
            company = company[1:]
    return company

import csv

# Function to write user data to users.csv
def write_users_to_csv(users):
    with open('users.csv', 'w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['login', 'name', 'company', 'location', 'email', 'hireable', 'bio', 'public_repos', 'followers', 'following', 'created_at'])
        for user in users:
            writer.writerow([user['login'], user.get('name', ''), clean_company(user.get('company', '')),
                             user.get('location', ''), user.get('email', ''), user.get('hireable', False),
                             user.get('bio', ''), user.get('public_repos', 0), user.get('followers', 0),
                             user.get('following', 0), user.get('created_at', '')])

# Function to write repository data to repositories.csv
def write_repositories_to_csv(repositories):
    with open('repositories.csv', 'w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['login', 'full_name', 'created_at', 'stargazers_count', 'watchers_count', 'language', 'has_projects', 'has_wiki', 'license_name'])

        for repo in repositories:
            license_name = repo.get('license', {}).get('name', '') if repo.get('license') else ''  # Check if license exists
            writer.writerow([repo['owner']['login'], repo['full_name'], repo['created_at'],
                             repo['stargazers_count'], repo['watchers_count'], repo.get('language', ''),
                             repo['has_projects'], repo['has_wiki'], license_name])


# Write the data to CSV files
write_users_to_csv(users)
write_repositories_to_csv(all_repositories)

from google.colab import files

# Download users.csv
files.download('users.csv')

# Download repositories.csv
files.download('repositories.csv')